# Load Test Analysis - 100 Requests, 20 Concurrent

## 测试配置

```bash
python tests/load_test.py \
  --url http://localhost:80 \
  --image-url "https://test-r2.zhizitech.org/test_discord_2.png" \
  --disable-cache \
  --concurrent 20 \
  --requests 100
```

**参数**：
- 总请求数：100
- 并发数：20
- 禁用缓存：是
- 测试图片：Discord 聊天截图

## 测试结果

### 整体统计

```
Total Requests:      100
Successful:          98 (98.0%)
Failed:              2 (2.0%)
Total Time:          77.97s
Requests/Second:     1.28
```

**分析**：
- ✅ **成功率很高**：98%（98/100）
- ⚠️ **2 个请求失败**：这解释了为什么 generation (85) < merge_step (99)
- 🐌 **吞吐量较低**：1.28 req/s（每秒只能处理 1.28 个请求）
- ⏱️ **总耗时**：77.97 秒（约 1.3 分钟）

### 响应时间统计

```
Response Time Stats:
Min:               1.597s
Max:               23.607s
Mean:              13.571s
Median:            14.147s
Std Dev:           4.587s

Percentiles:
P50:               14.240s
P90:               22.488s
P95:               22.923s
P99:               23.607s
```

**分析**：
- 🔴 **平均响应时间很长**：13.6 秒
- 🔴 **最慢请求**：23.6 秒（几乎是平均值的 2 倍）
- 📊 **变化很大**：最快 1.6 秒，最慢 23.6 秒（差距 14.8 倍）
- 🔴 **P90 很高**：22.5 秒（10% 的请求超过 22 秒）
- 🟡 **标准差大**：4.6 秒（说明响应时间不稳定）

### 失败分析

```
Status Codes:
200:               98 (98.0%)
500:               2 (2.0%)

Errors:
Reply generation failed: An error occurred during generation 1
Reply generation failed: Failed to parse reply text as JSON: 1
```

**失败原因**：
1. **Generation 错误**：1 次（可能是 LLM 调用失败）
2. **JSON 解析失败**：1 次（LLM 返回了无效的 JSON）

**这解释了为什么**：
- merge_step: 99 次（100 - 1 个完全失败）
- generation: 85 次（99 - 2 个 generation 失败 - 其他原因）

等等，数字不对：99 - 2 = 97，但实际是 85。让我重新分析...

## 深入分析

### 为什么 generation (85) 比 merge_step (99) 少 14 次？

根据负载测试结果：
- **总请求**：100
- **成功**：98
- **失败**：2

但 trace 显示：
- **merge_step**：99 次
- **generation**：85 次
- **差异**：14 次

**可能的解释**：

#### 1. 失败的 2 个请求
- 1 个在 generation 阶段失败
- 1 个 JSON 解析失败（generation 完成但解析失败）
- 这解释了 2 次差异

#### 2. 剩余的 12 次差异
可能的原因：
- **并发限制**：某些请求可能在队列中等待，merge_step 完成但 generation 还没开始
- **测试中断**：测试可能在某些请求完成 merge_step 但还没完成 generation 时结束
- **超时**：某些 generation 请求超时，但 merge_step 已完成
- **缓存问题**：虽然禁用了缓存，但可能有其他缓存机制

#### 3. 最可能的原因：测试结束时机
负载测试在 77.97 秒后结束，此时：
- 所有 100 个请求都已发送
- 98 个请求完全成功（merge_step + generation）
- 2 个请求失败
- 但可能有一些请求的 generation 还在进行中，trace 还没记录完

### 响应时间分解

根据之前的 trace 分析：
- **merge_step 平均**：9.3 秒
- **generation 平均**：3.5 秒
- **理论总时间**：12.8 秒

但负载测试显示：
- **实际平均响应时间**：13.6 秒

**差异分析**：
- 理论：12.8 秒
- 实际：13.6 秒
- 差异：0.8 秒（6.3%）

**额外开销来源**：
- 网络延迟
- 队列等待时间
- 其他中间件处理
- 日志记录

### 并发性能分析

#### 吞吐量
- **实际**：1.28 req/s
- **理论最大**：20 (并发) / 12.8s (平均响应时间) = 1.56 req/s
- **效率**：1.28 / 1.56 = 82%

**分析**：
- ✅ 并发效率还不错（82%）
- 🟡 但绝对吞吐量很低（1.28 req/s）
- 🔴 主要瓶颈是响应时间太长（13.6 秒）

#### 并发瓶颈
- **CPU**：可能不是瓶颈（LLM 调用是 I/O 密集型）
- **网络**：可能是瓶颈（LLM API 调用）
- **LLM API 限流**：可能是主要瓶颈

### 响应时间分布

```
Min:    1.597s  (最快的 1%)
P50:   14.240s  (中位数)
P90:   22.488s  (最慢的 10%)
Max:   23.607s  (最慢的 1%)
```

**分布特点**：
- 📊 **双峰分布**：最快的 1.6 秒，大部分在 14 秒左右
- 🔴 **长尾严重**：P90 是中位数的 1.58 倍
- ⚠️ **最快请求异常**：1.6 秒远低于平均值（可能是缓存命中或错误）

**最快请求分析**：
- 1.6 秒远低于理论最小值（merge_step 最小 5.7 秒）
- **可能原因**：
  1. 请求失败（快速失败）
  2. 缓存命中（虽然禁用了缓存）
  3. 某些请求跳过了 merge_step

## 性能瓶颈总结

### 1. 响应时间瓶颈（主要）
- **merge_step**：9.3 秒（占 69%）
- **generation**：3.5 秒（占 26%）
- **其他开销**：0.8 秒（占 5%）

### 2. 并发瓶颈（次要）
- **LLM API 限流**：可能限制了并发数
- **网络带宽**：图片上传可能占用带宽
- **服务器资源**：CPU/内存使用率需要监控

### 3. 稳定性问题
- **2% 失败率**：需要改进错误处理
- **响应时间不稳定**：标准差 4.6 秒（34% 的平均值）
- **长尾严重**：P90 是中位数的 1.58 倍

## 优化建议

### 短期优化（1-2 周）

#### 1. 减少响应时间（目标：-40%）
- **优化 merge_step prompt**：减少 2-3 秒
- **使用更快的模型**：减少 2-3 秒
- **目标**：平均响应时间从 13.6 秒降到 8 秒

#### 2. 提高稳定性（目标：99% 成功率）
- **改进 JSON 解析**：使用我们新的 fallback 机制
- **添加重试机制**：对失败的请求自动重试
- **更好的错误处理**：避免 500 错误

#### 3. 减少长尾（目标：P90 < 15 秒）
- **设置超时**：避免超长等待
- **优化慢请求**：分析 P90 以上的请求

### 中期优化（1 个月）

#### 1. 提高吞吐量（目标：3-5 req/s）
- **增加并发数**：测试 50-100 并发
- **优化资源使用**：减少内存占用
- **负载均衡**：多实例部署

#### 2. 改善用户体验
- **流式响应**：先返回 merge_step，再返回 generation
- **进度提示**：显示处理进度
- **预热机制**：提前处理部分请求

### 长期优化（2-3 个月）

#### 1. 架构优化
- **异步处理**：使用消息队列
- **结果缓存**：缓存常见场景
- **CDN 加速**：图片处理加速

#### 2. 成本优化
- **模型选择**：根据场景选择合适的模型
- **批量处理**：合并多个请求
- **智能路由**：根据负载选择服务器

## 性能目标

### 当前性能
| 指标 | 当前值 | 等级 |
|------|--------|------|
| 平均响应时间 | 13.6s | 🔴 差 |
| P90 响应时间 | 22.5s | 🔴 差 |
| 吞吐量 | 1.28 req/s | 🔴 差 |
| 成功率 | 98% | 🟡 一般 |

### 短期目标（1-2 周）
| 指标 | 目标值 | 改进 |
|------|--------|------|
| 平均响应时间 | 8s | -41% |
| P90 响应时间 | 15s | -33% |
| 吞吐量 | 2 req/s | +56% |
| 成功率 | 99% | +1% |

### 中期目标（1 个月）
| 指标 | 目标值 | 改进 |
|------|--------|------|
| 平均响应时间 | 6s | -56% |
| P90 响应时间 | 10s | -56% |
| 吞吐量 | 4 req/s | +213% |
| 成功率 | 99.5% | +1.5% |

### 长期目标（2-3 个月）
| 指标 | 目标值 | 改进 |
|------|--------|------|
| 平均响应时间 | 4s | -71% |
| P90 响应时间 | 7s | -69% |
| 吞吐量 | 8 req/s | +525% |
| 成功率 | 99.9% | +1.9% |

## 监控建议

### 1. 实时监控
```python
# 添加到 orchestrator.py
logger.info(f"Request completed: {total_time}ms, merge={merge_time}ms, gen={gen_time}ms")
```

### 2. 告警阈值
- 平均响应时间 > 20 秒 → 告警
- P90 响应时间 > 30 秒 → 告警
- 失败率 > 5% → 告警
- 吞吐量 < 1 req/s → 告警

### 3. 定期负载测试
```bash
# 每天运行一次
python tests/load_test.py \
  --url http://localhost:80 \
  --image-url "https://test-r2.zhizitech.org/test_discord_2.png" \
  --disable-cache \
  --concurrent 20 \
  --requests 100 \
  > reports/load_test_$(date +%Y%m%d).txt
```

## 结论

1. ✅ **成功率不错**：98%，但需要提高到 99%+
2. 🔴 **响应时间太长**：13.6 秒，需要减少到 8 秒以下
3. 🔴 **吞吐量太低**：1.28 req/s，需要提高到 3-5 req/s
4. 🔴 **长尾严重**：P90 是中位数的 1.58 倍，需要优化
5. ✅ **并发效率还可以**：82%，但绝对值太低
6. ⚠️ **14 个 generation 缺失**：主要是失败和测试结束时机导致

## 下一步行动

1. **立即**：
   - 分析失败的 2 个请求的详细日志
   - 检查 `failed_json_replies/` 目录

2. **本周**：
   - 优化 merge_step prompt（目标：减少 2-3 秒）
   - 改进 JSON 解析错误处理

3. **下周**：
   - 测试更快的模型（gemini-2.0-flash-exp）
   - 重新运行负载测试，验证改进效果

4. **本月**：
   - 实现流式响应
   - 提高并发数到 50

## 更新日期

2026-02-05
