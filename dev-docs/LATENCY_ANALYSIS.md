# Latency Analysis - Merge Step vs Generation

## 修复后的数据

```
LATENCY SUMMARY BY TASK_TYPE
--------------------------------------------------------------------------------
Type                              N   Mean(ms)        P50        P90        Min        Max
--------------------------------------------------------------------------------
merge_step                       99       9349       7971      12459       5677      12860
generation                       85       3505       1956       7463       1548       8324
```

## 关键发现

### 1. 调用次数比例

- **merge_step**: 99 次
- **generation**: 85 次
- **比例**: 85/99 = **0.86:1**

**分析**：
- ✅ 双重统计问题已修复（从 1.72:1 降到 0.86:1）
- ⚠️ generation 比 merge_step **少 14 次**（99 - 85 = 14）

**可能原因**：
1. **部分请求失败**：14 个请求在 merge_step 后失败，没有进入 generation
2. **缓存命中**：部分请求使用了缓存的 generation 结果
3. **测试场景**：某些测试只运行了 merge_step，没有 generation
4. **错误处理**：merge_step 成功但 generation 因某些原因被跳过

### 2. 延迟对比

#### Merge Step（截图解析）
- **平均延迟**: 9,349 ms (约 9.3 秒)
- **中位数 (P50)**: 7,971 ms (约 8 秒)
- **P90**: 12,459 ms (约 12.5 秒)
- **范围**: 5,677 ms ~ 12,860 ms

**特点**：
- 🐌 **非常慢**：平均 9.3 秒
- 📊 **变化较大**：最快 5.7 秒，最慢 12.9 秒（差距 2.3 倍）
- 🔴 **P90 很高**：12.5 秒，说明 10% 的请求超过 12 秒

#### Generation（回复生成）
- **平均延迟**: 3,505 ms (约 3.5 秒)
- **中位数 (P50)**: 1,956 ms (约 2 秒)
- **P90**: 7,463 ms (约 7.5 秒)
- **范围**: 1,548 ms ~ 8,324 ms

**特点**：
- ⚡ **相对较快**：平均 3.5 秒
- 📊 **变化很大**：最快 1.5 秒，最慢 8.3 秒（差距 5.4 倍）
- 🟡 **P90 偏高**：7.5 秒，说明 10% 的请求超过 7 秒

### 3. 性能对比

| 指标 | Merge Step | Generation | 比例 |
|------|-----------|-----------|------|
| 平均延迟 | 9,349 ms | 3,505 ms | **2.67x** |
| 中位数 (P50) | 7,971 ms | 1,956 ms | **4.08x** |
| P90 | 12,459 ms | 7,463 ms | **1.67x** |
| 最小值 | 5,677 ms | 1,548 ms | **3.67x** |
| 最大值 | 12,860 ms | 8,324 ms | **1.54x** |

**结论**：
- 🔴 **Merge Step 是主要瓶颈**：比 generation 慢 2.67 倍（平均）
- 🔴 **中位数差距更大**：merge_step 的 P50 是 generation 的 4 倍
- 🟡 **两者都有长尾问题**：P90 都明显高于中位数

## 深入分析

### Merge Step 为什么这么慢？

#### 1. 多模态 LLM 调用
- 需要处理图片（base64 编码）
- 图片数据量大，传输慢
- 多模态模型推理慢

#### 2. Prompt 复杂度
- merge_step 的 prompt 很长（包含详细的 schema）
- 需要解析复杂的对话结构
- 输出 JSON 结构复杂

#### 3. Token 数量
让我们检查一下 token 使用情况：

```bash
# 查看 merge_step 的 token 统计
python scripts/analyze_trace.py logs/trace.jsonl | grep -A 5 "merge_step"
```

预期：
- merge_step 的 input tokens 应该远大于 generation
- 图片处理可能占用大量 tokens

### Generation 为什么有长尾？

#### 1. 变化很大
- 最快：1.5 秒
- 最慢：8.3 秒
- 差距：5.4 倍

#### 2. 可能原因
- **重试机制**：某些请求可能重试了（虽然禁用了亲密度检查）
- **模型选择**：不同的 quality 使用不同的模型
- **网络波动**：LLM API 响应时间不稳定
- **Prompt 长度**：不同的对话历史长度

### 为什么 generation 少 14 次？

让我们检查一下：

```bash
# 查看失败的请求
grep "error\|failed\|exception" logs/trace.jsonl | grep -i generation
```

可能的情况：
1. **merge_step 成功，但 generation 失败**
2. **某些测试场景只测试 merge_step**
3. **缓存命中**（虽然不太可能）

## 性能优化建议

### 1. 优化 Merge Step（优先级：高）

#### 方案 A：减少 Prompt 长度
- 简化 schema 描述
- 移除不必要的示例
- 使用更简洁的指令

**预期收益**：减少 20-30% 的延迟

#### 方案 B：优化图片处理
- 压缩图片（降低分辨率）
- 使用更高效的编码
- 考虑图片预处理

**预期收益**：减少 10-20% 的延迟

#### 方案 C：使用更快的模型
- 尝试 `gemini-2.0-flash-exp`（更快）
- 或 `gpt-4o-mini`（更便宜更快）

**预期收益**：减少 30-50% 的延迟

#### 方案 D：并行处理
- 如果有多个图片，并行调用 merge_step
- 使用 asyncio.gather()

**预期收益**：多图片场景下减少 40-60% 的延迟

### 2. 优化 Generation（优先级：中）

#### 方案 A：减少长尾
- 设置更短的 timeout
- 使用更稳定的模型
- 添加快速失败机制

**预期收益**：P90 从 7.5 秒降到 5 秒

#### 方案 B：缓存优化
- 缓存常见场景的回复
- 使用 Redis 缓存

**预期收益**：缓存命中时延迟 < 100ms

### 3. 整体优化（优先级：中）

#### 方案 A：流式响应
- 先返回 merge_step 结果
- 再流式返回 generation 结果

**预期收益**：用户感知延迟减少 50%

#### 方案 B：预热
- 预先调用 merge_step（在用户上传图片时）
- 减少等待时间

**预期收益**：总延迟减少 30-40%

## 性能目标

### 当前性能
- **总延迟**: 9.3s (merge_step) + 3.5s (generation) = **12.8 秒**
- **P50 总延迟**: 8.0s + 2.0s = **10 秒**

### 目标性能（优化后）
- **总延迟**: < 6 秒（减少 50%）
- **P50 总延迟**: < 4 秒（减少 60%）
- **P90 总延迟**: < 8 秒（减少 40%）

### 实现路径
1. **短期**（1-2 周）：
   - 优化 merge_step prompt（减少 2-3 秒）
   - 使用更快的模型（减少 2-3 秒）
   - **预期总延迟**: 8-9 秒

2. **中期**（1 个月）：
   - 实现流式响应（改善用户体验）
   - 添加缓存机制（部分请求 < 1 秒）
   - **预期总延迟**: 6-7 秒

3. **长期**（2-3 个月）：
   - 图片预处理和压缩
   - 并行处理优化
   - **预期总延迟**: 4-5 秒

## 监控建议

### 1. 添加详细的性能指标
```python
# 在 orchestrator.py 中添加
logger.info(f"merge_step: {merge_duration}ms, tokens: {input_tokens}/{output_tokens}")
logger.info(f"generation: {gen_duration}ms, tokens: {input_tokens}/{output_tokens}")
```

### 2. 设置告警阈值
- merge_step P90 > 15 秒 → 告警
- generation P90 > 10 秒 → 告警
- 总延迟 P90 > 20 秒 → 告警

### 3. 定期分析
```bash
# 每天运行一次
python scripts/analyze_trace.py logs/trace_$(date +%Y%m%d).jsonl > reports/daily_$(date +%Y%m%d).txt
```

## 结论

1. ✅ **双重统计已修复**：generation 从 170 降到 85
2. 🔴 **Merge Step 是主要瓶颈**：平均 9.3 秒，占总延迟的 73%
3. 🟡 **Generation 有长尾问题**：P90 达到 7.5 秒
4. ⚠️ **14 个请求缺失**：需要调查为什么 generation 比 merge_step 少
5. 🎯 **优化重点**：先优化 merge_step，可以获得最大收益

## 下一步行动

1. **立即**：调查为什么有 14 个 generation 缺失
2. **本周**：优化 merge_step prompt，目标减少 2-3 秒
3. **下周**：测试更快的模型（gemini-2.0-flash-exp）
4. **本月**：实现流式响应，改善用户体验

## 更新日期

2026-02-05
