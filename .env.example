# Application Settings
DEBUG=false

# LLM Configuration
LLM_DEFAULT_PROVIDER=openai
LLM_DEFAULT_MODEL=gpt-4
LLM_FALLBACK_MODEL=gpt-3.5-turbo
LLM_CHEAP_MODEL=gpt-3.5-turbo
LLM_PREMIUM_MODEL=gpt-4-turbo

# Orchestrator Configuration
ORCHESTRATOR_MAX_RETRIES=3
ORCHESTRATOR_TIMEOUT_SECONDS=30.0
ORCHESTRATOR_RETRY_DELAY_SECONDS=0.5
ORCHESTRATOR_EXPONENTIAL_BACKOFF=true

# Billing Configuration
BILLING_COST_LIMIT_USD=0.1
BILLING_DEFAULT_USER_QUOTA_USD=10.0

# Database Configuration
DB_URL=sqlite+aiosqlite:///./conversation.db
DB_ECHO=false

# CORS Settings (comma-separated for multiple origins)
CORS_ORIGINS=["*"]

# Prompt Optimization Configuration (Phase 3: Output Optimization)
# Control whether reasoning fields are included in LLM outputs
PROMPT_INCLUDE_REASONING=false

# Maximum tokens for reply generation (20-500)
PROMPT_MAX_REPLY_TOKENS=100

# Use compact output schemas to reduce tokens
PROMPT_USE_COMPACT_SCHEMAS=true
