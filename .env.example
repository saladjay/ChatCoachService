# ============================================================================
# Application Settings / 应用程序设置
# ============================================================================
DEBUG=false


# ============================================================================
# LLM Configuration / LLM 配置
# ============================================================================

# Default LLM provider and models / 默认 LLM 提供商和模型
LLM_DEFAULT_PROVIDER=openai
LLM_DEFAULT_MODEL=gpt-4
LLM_FALLBACK_MODEL=gpt-3.5-turbo
LLM_CHEAP_MODEL=gpt-3.5-turbo
LLM_PREMIUM_MODEL=gpt-4-turbo

# Disable LLM quality-based routing / 禁用基于质量的 LLM 路由
# When true, only uses default provider without fallback / 为 true 时，仅使用默认提供商，不进行回退
LLM_DISABLE_QUALITY_ROUTING=false

# Multimodal image transport format / 多模态图片传输格式
# base64: Compress and encode image as base64 (recommended, works with all providers)
#         压缩并编码图片为 base64（推荐，适用于所有提供商）
# url: Send image URL directly (faster but URL must be publicly accessible)
#      直接发送图片 URL（更快但 URL 必须可公开访问）
#      Note: DashScope cannot access localhost or internal network URLs (192.168.x.x)
#      注意：DashScope 无法访问 localhost 或内网 URL（192.168.x.x）
LLM_MULTIMODAL_IMAGE_FORMAT=base64

# Compress images before sending to LLM / 发送到 LLM 前是否压缩图片
# true: Compress images to 800px max dimension (saves tokens, faster)
#       压缩图片到最大 800px（节省 token，更快）
# false: Use original image size (better quality, more tokens)
#        使用原始图片尺寸（更好的质量，更多 token）
LLM_MULTIMODAL_IMAGE_COMPRESS=true

# LLM adapter automatic logging / LLM 适配器自动日志记录
# Enable automatic logging of time, tokens, and cost / 启用时间、token 和成本的自动日志记录
LLM_ADAPTER_LOGGING=false
LLM_ADAPTER_LOG_DIR=./llm-adapter-logs


# ============================================================================
# LLM Provider API Keys / LLM 提供商 API 密钥
# ============================================================================

# OpenRouter API (provides access to multiple vision models) / OpenRouter API（提供多个视觉模型访问）
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Alibaba DashScope API / 阿里云灵积 API
DASHSCOPE_API_KEY=your_dashscope_api_key_here
DASHSCOPE_BASE_URL=https://dashscope.aliyuncs.com/api/v1

# Google Cloud Vertex AI Configuration / Google Cloud Vertex AI 配置
# Path to service account JSON file / 服务账号 JSON 文件路径
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account.json


# ============================================================================
# Orchestrator Configuration / 编排器配置
# ============================================================================

# Retry and timeout settings / 重试和超时设置
ORCHESTRATOR_MAX_RETRIES=3
ORCHESTRATOR_TIMEOUT_SECONDS=30.0
ORCHESTRATOR_RETRY_DELAY_SECONDS=0.5
ORCHESTRATOR_EXPONENTIAL_BACKOFF=true

# Feature flags / 功能开关
# Never use reply redis cache / 不使用回复 Redis 缓存
NO_REPLY_CACHE=false

# Disable persona cache / 禁用人设缓存
NO_PERSONA_CACHE=false

# Disable strategy planner / 禁用策略规划器
NO_STRATEGY_PLANNER=false

# Disable intimacy check / 禁用亲密度检查
NO_INTIMACY_CHECK=false

# Use merge step (combines screenshot analysis + context summary + scenario analysis)
# 使用合并步骤（合并截图分析 + 上下文摘要 + 场景分析）
# When enabled, uses a single LLM call instead of three separate calls for improved performance
# 启用时，使用单个 LLM 调用而不是三个独立调用以提高性能
USE_MERGE_STEP=false


# ============================================================================
# Prompt Configuration / 提示词配置
# ============================================================================

# Maximum number of recent messages for context / 上下文中最近消息的最大数量
PROMPT_CONTEXT_MAX_MESSAGES=20

# Prompt Optimization (Phase 3: Output Optimization) / 提示词优化（第三阶段：输出优化）
# Include reasoning fields in LLM outputs / 在 LLM 输出中包含推理字段
PROMPT_INCLUDE_REASONING=false

# Maximum tokens for reply generation (20-500) / 回复生成的最大 token 数（20-500）
PROMPT_MAX_REPLY_TOKENS=100

# Use compact output schemas to reduce tokens / 使用紧凑的输出模式以减少 token
PROMPT_USE_COMPACT_SCHEMAS=true


# ============================================================================
# Billing Configuration / 计费配置
# ============================================================================

# Cost limits / 成本限制
BILLING_COST_LIMIT_USD=0.1
BILLING_DEFAULT_USER_QUOTA_USD=10.0


# ============================================================================
# Database Configuration / 数据库配置
# ============================================================================

# SQLite database URL / SQLite 数据库 URL
DB_URL=sqlite+aiosqlite:///./conversation.db
DB_ECHO=false


# ============================================================================
# Cache Configuration / 缓存配置
# ============================================================================

# Redis cache URL / Redis 缓存 URL
CACHE_REDIS_URL=redis://127.0.0.1:6379/0


# ============================================================================
# Logging Configuration / 日志配置
# ============================================================================

# Log failed JSON replies to file for debugging / 将失败的 JSON 回复记录到文件以便调试
# Saves complete raw LLM responses that failed to parse as JSON
# 保存解析为 JSON 失败的完整原始 LLM 响应
# Files saved to: logs/failed_json_replies/ / 文件保存到：logs/failed_json_replies/
LOG_FAILED_JSON_REPLIES=false


# ============================================================================
# Trace Logging Configuration / 追踪日志配置
# ============================================================================

# Enable trace logging / 启用追踪日志
# Detailed logging of all LLM calls and processing steps
# 所有 LLM 调用和处理步骤的详细日志
TRACE_ENABLED=false

# Trace log level (error, info, debug) / 追踪日志级别（error, info, debug）
# - error: Only log errors / 仅记录错误
# - info: Log major steps and LLM calls (recommended) / 记录主要步骤和 LLM 调用（推荐）
# - debug: Log all details including intermediate steps / 记录所有详细信息，包括中间步骤
TRACE_LEVEL=info

# Trace log file path / 追踪日志文件路径
TRACE_FILE_PATH=logs/trace.jsonl

# Log LLM prompts / 记录 LLM 提示词
# When enabled, logs full prompts, responses, tokens, costs, and timing
# 启用时，记录完整的提示词、响应、token、成本和时间
TRACE_LOG_LLM_PROMPT=false

# Log timing information for performance monitoring / 记录时间信息以进行性能监控
# Requires TRACE_ENABLED=true / 需要 TRACE_ENABLED=true
# Logs detailed timing for each step: screenshot analysis, scenario analysis, reply generation, etc.
# 记录每个步骤的详细时间：截图分析、场景分析、回复生成等
TRACE_LOG_TIMING=false


# ============================================================================
# CORS Settings / CORS 设置
# ============================================================================

# Allowed origins (comma-separated for multiple origins) / 允许的来源（多个来源用逗号分隔）
CORS_ORIGINS=["*"]


# ============================================================================
# Proxy Configuration / 代理配置
# ============================================================================

# Proxy settings for Google Cloud (if needed) / Google Cloud 代理设置（如需要）
# Uncomment and configure if you need to use a proxy / 如需使用代理，请取消注释并配置
# HTTP_PROXY=http://your-proxy-server:port
# HTTPS_PROXY=http://your-proxy-server:port
# GRPC_PROXY=http://your-proxy-server:port
