# Application Settings
DEBUG=false

# LLM Configuration
LLM_DEFAULT_PROVIDER=openai
LLM_DEFAULT_MODEL=gpt-4
LLM_FALLBACK_MODEL=gpt-3.5-turbo
LLM_CHEAP_MODEL=gpt-3.5-turbo
LLM_PREMIUM_MODEL=gpt-4-turbo

# Orchestrator Configuration
ORCHESTRATOR_MAX_RETRIES=3
ORCHESTRATOR_TIMEOUT_SECONDS=30.0
ORCHESTRATOR_RETRY_DELAY_SECONDS=0.5
ORCHESTRATOR_EXPONENTIAL_BACKOFF=true

# Billing Configuration
BILLING_COST_LIMIT_USD=0.1
BILLING_DEFAULT_USER_QUOTA_USD=10.0

# Database Configuration
DB_URL=sqlite+aiosqlite:///./conversation.db
DB_ECHO=false

# CORS Settings (comma-separated for multiple origins)
CORS_ORIGINS=["*"]

# 控制对话总结从最近多少个对话中产生
PROMPT_CONTEXT_MAX_MESSAGES=20

# Prompt Optimization Configuration (Phase 3: Output Optimization)
# Control whether reasoning fields are included in LLM outputs
PROMPT_INCLUDE_REASONING=false

# Maximum tokens for reply generation (20-500)
PROMPT_MAX_REPLY_TOKENS=100

# Use compact output schemas to reduce tokens
PROMPT_USE_COMPACT_SCHEMAS=true

# OpenRouter API Configuration
# OpenRouter provides access to multiple vision models through a unified API
OPENROUTER_API_KEY=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
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# never use reply redis cache
NO_REPLY_CACHE=true
NO_STRATEGY_PLANNER=true
NO_PERSONA_CACHE = true

# REDIS
CACHE_REDIS_URL=redis://127.0.0.1:6379/0