# å¢å¼ºåŠŸèƒ½ (Enhancements)

**ç›®æ ‡**: ä¸ºç°æœ‰ç³»ç»Ÿæ·»åŠ ç›‘æ§ã€A/B æµ‹è¯•ç­‰åŠŸèƒ½  
**é¢„è®¡æ—¶é—´**: 2-3 å‘¨  
**ä¼˜å…ˆçº§**: â­ ä¸­ä½

---

## ğŸ“‹ æ¦‚è¿°

åœ¨å®Œæˆæ ¸å¿ƒä¼˜åŒ–åï¼Œå¯ä»¥æ·»åŠ ä¸€äº›å¢å¼ºåŠŸèƒ½æ¥æå‡ç³»ç»Ÿçš„å¯è§‚æµ‹æ€§ã€å¯æµ‹è¯•æ€§å’Œå¯ç»´æŠ¤æ€§ã€‚

---

## ğŸ¯ å¢å¼ºåŠŸèƒ½åˆ—è¡¨

### 1. Token ä½¿ç”¨ç›‘æ§ä»ªè¡¨æ¿ ğŸ“Š

**ç›®æ ‡**: å®æ—¶ç›‘æ§ token ä½¿ç”¨æƒ…å†µ

**åŠŸèƒ½**:
- å®æ—¶ token ä½¿ç”¨ç»Ÿè®¡
- æŒ‰æ—¶é—´æ®µæŸ¥çœ‹è¶‹åŠ¿
- æŒ‰ç”¨æˆ·/åœºæ™¯åˆ†ç»„
- æˆæœ¬é¢„æµ‹å’Œå‘Šè­¦

**å®ç°**:
```python
# app/services/token_monitor.py

class TokenMonitor:
    """Token ä½¿ç”¨ç›‘æ§æœåŠ¡"""
    
    def __init__(self, storage: MetricsStorage):
        self.storage = storage
    
    async def record_usage(self, usage: TokenUsage):
        """è®°å½• token ä½¿ç”¨"""
        await self.storage.save({
            "timestamp": datetime.now(),
            "user_id": usage.user_id,
            "task_type": usage.task_type,
            "input_tokens": usage.input_tokens,
            "output_tokens": usage.output_tokens,
            "total_tokens": usage.total_tokens,
            "cost_usd": usage.cost_usd,
            "model": usage.model,
            "provider": usage.provider
        })
    
    async def get_stats(
        self,
        start_time: datetime,
        end_time: datetime,
        group_by: str = "hour"
    ) -> Dict:
        """è·å–ç»Ÿè®¡æ•°æ®"""
        data = await self.storage.query(start_time, end_time)
        
        # æŒ‰æ—¶é—´åˆ†ç»„
        grouped = self._group_by_time(data, group_by)
        
        return {
            "total_tokens": sum(d["total_tokens"] for d in data),
            "total_cost": sum(d["cost_usd"] for d in data),
            "avg_tokens_per_request": mean([d["total_tokens"] for d in data]),
            "timeline": grouped
        }
```

**ä»ªè¡¨æ¿ç•Œé¢**:
```
Token ä½¿ç”¨ç›‘æ§ä»ªè¡¨æ¿
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š ä»Šæ—¥ç»Ÿè®¡ (2026-01-22)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ€»è¯·æ±‚æ•°: 10,000                                             â”‚
â”‚ æ€» Token: 12,500,000                                         â”‚
â”‚ æ€»æˆæœ¬: $62.50                                               â”‚
â”‚ å¹³å‡ Token/è¯·æ±‚: 1,250                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ“ˆ Token ä½¿ç”¨è¶‹åŠ¿ (æœ€è¿‘ 24 å°æ—¶)
  2000 â”¤                                    â•­â”€â•®
  1800 â”¤                              â•­â”€â”€â”€â”€â”€â•¯ â•°â”€â•®
  1600 â”¤                        â•­â”€â”€â”€â”€â”€â•¯         â•°â”€â•®
  1400 â”¤                  â•­â”€â”€â”€â”€â”€â•¯                 â•°â”€â•®
  1200 â”¤            â•­â”€â”€â”€â”€â”€â•¯                         â•°â”€â•®
  1000 â”¤      â•­â”€â”€â”€â”€â”€â•¯                                 â•°â”€â•®
   800 â”¤â•­â”€â”€â”€â”€â”€â•¯                                         â•°â”€â•®
       â””â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€
        00:00 03:00 06:00 09:00 12:00 15:00 18:00 21:00 24:00

ğŸ’° æˆæœ¬åˆ†å¸ƒ (æŒ‰ä»»åŠ¡ç±»å‹)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åœºæ™¯åˆ†æ:     $12.50 (20%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                         â”‚
â”‚ ç­–ç•¥è§„åˆ’:     $18.75 (30%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                     â”‚
â”‚ å›å¤ç”Ÿæˆ:     $31.25 (50%) â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ¯ ä¼˜åŒ–å»ºè®®
â€¢ åœºæ™¯åˆ†æå¯ä»¥ä½¿ç”¨æ›´ä¾¿å®œçš„æ¨¡å‹ (é¢„è®¡èŠ‚çœ $5/å¤©)
â€¢ ä½äº²å¯†åº¦å¯¹è¯å¯ä»¥å‡å°‘ max_tokens (é¢„è®¡èŠ‚çœ $8/å¤©)
```

---

### 2. A/B æµ‹è¯•æ¡†æ¶ ğŸ§ª

**ç›®æ ‡**: ç³»ç»ŸåŒ–åœ°æµ‹è¯•ä¸åŒé…ç½®

**åŠŸèƒ½**:
- é…ç½®å¤šä¸ªæµ‹è¯•å˜ä½“
- è‡ªåŠ¨æµé‡åˆ†é…
- å®æ—¶ç»“æœå¯¹æ¯”
- ç»Ÿè®¡æ˜¾è‘—æ€§æ£€éªŒ

**å®ç°**:
```python
# app/services/ab_testing.py

class ABTestFramework:
    """A/B æµ‹è¯•æ¡†æ¶"""
    
    def __init__(self):
        self.experiments = {}
        self.results = {}
    
    def create_experiment(
        self,
        name: str,
        variants: Dict[str, PromptConfig],
        traffic_split: Dict[str, float]
    ):
        """åˆ›å»ºå®éªŒ
        
        Args:
            name: å®éªŒåç§°
            variants: å˜ä½“é…ç½® {"A": config_a, "B": config_b}
            traffic_split: æµé‡åˆ†é… {"A": 0.5, "B": 0.5}
        """
        self.experiments[name] = {
            "variants": variants,
            "traffic_split": traffic_split,
            "start_time": datetime.now(),
            "status": "running"
        }
    
    def assign_variant(self, experiment_name: str, user_id: str) -> str:
        """ä¸ºç”¨æˆ·åˆ†é…å˜ä½“"""
        experiment = self.experiments[experiment_name]
        
        # åŸºäºç”¨æˆ· ID çš„ä¸€è‡´æ€§å“ˆå¸Œ
        hash_value = hash(f"{experiment_name}:{user_id}") % 100
        
        cumulative = 0
        for variant, split in experiment["traffic_split"].items():
            cumulative += split * 100
            if hash_value < cumulative:
                return variant
        
        return list(experiment["variants"].keys())[0]
    
    def record_result(
        self,
        experiment_name: str,
        variant: str,
        metrics: Dict
    ):
        """è®°å½•å®éªŒç»“æœ"""
        if experiment_name not in self.results:
            self.results[experiment_name] = {}
        
        if variant not in self.results[experiment_name]:
            self.results[experiment_name][variant] = []
        
        self.results[experiment_name][variant].append(metrics)
    
    def analyze_experiment(self, experiment_name: str) -> Dict:
        """åˆ†æå®éªŒç»“æœ"""
        results = self.results[experiment_name]
        
        analysis = {}
        for variant, data in results.items():
            analysis[variant] = {
                "sample_size": len(data),
                "avg_tokens": mean([d["total_tokens"] for d in data]),
                "avg_cost": mean([d["cost_usd"] for d in data]),
                "avg_quality": mean([d["quality_score"] for d in data]),
                "avg_latency": mean([d["latency_ms"] for d in data])
            }
        
        # è®¡ç®—ç»Ÿè®¡æ˜¾è‘—æ€§
        if len(results) == 2:
            variants = list(results.keys())
            significance = self._calculate_significance(
                results[variants[0]],
                results[variants[1]]
            )
            analysis["significance"] = significance
        
        return analysis
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
# åˆ›å»ºå®éªŒ
ab_test = ABTestFramework()
ab_test.create_experiment(
    name="reasoning_control_test",
    variants={
        "A": PromptConfig(include_reasoning=True, max_reply_tokens=200),
        "B": PromptConfig(include_reasoning=False, max_reply_tokens=100)
    },
    traffic_split={"A": 0.5, "B": 0.5}
)

# åœ¨è¯·æ±‚å¤„ç†ä¸­
variant = ab_test.assign_variant("reasoning_control_test", user_id)
config = ab_test.experiments["reasoning_control_test"]["variants"][variant]

# ä½¿ç”¨é…ç½®ç”Ÿæˆå›å¤
result = await generate_reply(config=config)

# è®°å½•ç»“æœ
ab_test.record_result(
    "reasoning_control_test",
    variant,
    {
        "total_tokens": result.total_tokens,
        "cost_usd": result.cost,
        "quality_score": evaluate_quality(result),
        "latency_ms": result.latency
    }
)

# åˆ†æç»“æœ
analysis = ab_test.analyze_experiment("reasoning_control_test")
print(analysis)
```

---

### 3. åŠ¨æ€ä¼˜åŒ– ğŸ”„

**ç›®æ ‡**: æ ¹æ®å®æ—¶æ•°æ®è‡ªåŠ¨è°ƒæ•´é…ç½®

**åŠŸèƒ½**:
- è‡ªåŠ¨æ£€æµ‹æ€§èƒ½é—®é¢˜
- åŠ¨æ€è°ƒæ•´ token é™åˆ¶
- è‡ªé€‚åº”æ¨¡å‹é€‰æ‹©
- è‡ªåŠ¨å›æ»šæœºåˆ¶

**å®ç°**:
```python
# app/services/dynamic_optimizer.py

class DynamicOptimizer:
    """åŠ¨æ€ä¼˜åŒ–å™¨"""
    
    def __init__(self, monitor: TokenMonitor):
        self.monitor = monitor
        self.current_config = PromptConfig.from_env()
        self.optimization_history = []
    
    async def optimize(self):
        """æ‰§è¡Œä¼˜åŒ–"""
        # è·å–æœ€è¿‘çš„æ€§èƒ½æ•°æ®
        stats = await self.monitor.get_stats(
            start_time=datetime.now() - timedelta(hours=1),
            end_time=datetime.now()
        )
        
        # åˆ†ææ˜¯å¦éœ€è¦ä¼˜åŒ–
        if self._should_optimize(stats):
            new_config = self._calculate_optimal_config(stats)
            
            # åº”ç”¨æ–°é…ç½®
            await self._apply_config(new_config)
            
            # è®°å½•ä¼˜åŒ–
            self.optimization_history.append({
                "timestamp": datetime.now(),
                "old_config": self.current_config,
                "new_config": new_config,
                "reason": self._explain_optimization(stats)
            })
            
            self.current_config = new_config
    
    def _should_optimize(self, stats: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ä¼˜åŒ–"""
        # æˆæœ¬è¿‡é«˜
        if stats["total_cost"] > COST_THRESHOLD:
            return True
        
        # Token ä½¿ç”¨è¿‡å¤š
        if stats["avg_tokens_per_request"] > TOKEN_THRESHOLD:
            return True
        
        # è´¨é‡ä¸‹é™
        if stats.get("avg_quality", 1.0) < QUALITY_THRESHOLD:
            return True
        
        return False
    
    def _calculate_optimal_config(self, stats: Dict) -> PromptConfig:
        """è®¡ç®—æœ€ä¼˜é…ç½®"""
        config = self.current_config.copy()
        
        # å¦‚æœæˆæœ¬è¿‡é«˜ï¼Œå‡å°‘ token é™åˆ¶
        if stats["total_cost"] > COST_THRESHOLD:
            config.max_reply_tokens = max(
                50,
                config.max_reply_tokens - 20
            )
        
        # å¦‚æœè´¨é‡ä¸‹é™ï¼Œå¢åŠ  token é™åˆ¶
        if stats.get("avg_quality", 1.0) < QUALITY_THRESHOLD:
            config.max_reply_tokens = min(
                200,
                config.max_reply_tokens + 20
            )
        
        return config
```

---

### 4. è´¨é‡ç›‘æ§ âœ…

**ç›®æ ‡**: æŒç»­ç›‘æ§å›å¤è´¨é‡

**åŠŸèƒ½**:
- è‡ªåŠ¨è´¨é‡è¯„ä¼°
- è´¨é‡è¶‹åŠ¿åˆ†æ
- å¼‚å¸¸æ£€æµ‹å’Œå‘Šè­¦
- è´¨é‡æŠ¥å‘Šç”Ÿæˆ

**å®ç°**:
```python
# app/services/quality_monitor.py

class QualityMonitor:
    """è´¨é‡ç›‘æ§æœåŠ¡"""
    
    def __init__(self, evaluator: QualityEvaluator):
        self.evaluator = evaluator
        self.quality_history = []
    
    async def evaluate_reply(
        self,
        request: ReplyGenerationInput,
        reply: LLMResult
    ) -> QualityScore:
        """è¯„ä¼°å›å¤è´¨é‡"""
        score = await self.evaluator.evaluate(request, reply)
        
        # è®°å½•è´¨é‡åˆ†æ•°
        self.quality_history.append({
            "timestamp": datetime.now(),
            "user_id": request.user_id,
            "scenario": request.scene.scenario,
            "intimacy_level": request.scene.intimacy_level,
            "score": score
        })
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦
        if score.overall < QUALITY_THRESHOLD:
            await self._send_alert(request, reply, score)
        
        return score
    
    async def get_quality_report(
        self,
        start_time: datetime,
        end_time: datetime
    ) -> Dict:
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        data = [
            d for d in self.quality_history
            if start_time <= d["timestamp"] <= end_time
        ]
        
        return {
            "period": f"{start_time} to {end_time}",
            "total_evaluations": len(data),
            "avg_quality": mean([d["score"].overall for d in data]),
            "quality_by_scenario": self._group_by_scenario(data),
            "quality_trend": self._calculate_trend(data),
            "alerts": self._get_alerts(start_time, end_time)
        }
```

---

### 5. æˆæœ¬é¢„æµ‹ ğŸ’°

**ç›®æ ‡**: é¢„æµ‹æœªæ¥çš„ token ä½¿ç”¨å’Œæˆæœ¬

**åŠŸèƒ½**:
- åŸºäºå†å²æ•°æ®é¢„æµ‹
- ä¸åŒåœºæ™¯çš„æˆæœ¬æ¨¡æ‹Ÿ
- é¢„ç®—å‘Šè­¦
- æˆæœ¬ä¼˜åŒ–å»ºè®®

**å®ç°**:
```python
# app/services/cost_predictor.py

class CostPredictor:
    """æˆæœ¬é¢„æµ‹æœåŠ¡"""
    
    def __init__(self, monitor: TokenMonitor):
        self.monitor = monitor
    
    async def predict_daily_cost(self) -> Dict:
        """é¢„æµ‹æ¯æ—¥æˆæœ¬"""
        # è·å–æœ€è¿‘ 7 å¤©çš„æ•°æ®
        history = await self.monitor.get_stats(
            start_time=datetime.now() - timedelta(days=7),
            end_time=datetime.now(),
            group_by="day"
        )
        
        # è®¡ç®—è¶‹åŠ¿
        daily_costs = [d["total_cost"] for d in history["timeline"]]
        trend = self._calculate_trend(daily_costs)
        
        # é¢„æµ‹æ˜å¤©çš„æˆæœ¬
        predicted_cost = daily_costs[-1] * (1 + trend)
        
        return {
            "predicted_daily_cost": predicted_cost,
            "trend": trend,
            "confidence": 0.85,
            "historical_avg": mean(daily_costs)
        }
    
    async def simulate_optimization(
        self,
        config: PromptConfig
    ) -> Dict:
        """æ¨¡æ‹Ÿä¼˜åŒ–æ•ˆæœ"""
        # è·å–å½“å‰æˆæœ¬
        current_stats = await self.monitor.get_stats(
            start_time=datetime.now() - timedelta(days=1),
            end_time=datetime.now()
        )
        
        # ä¼°ç®—ä¼˜åŒ–åçš„æˆæœ¬
        # (åŸºäº Phase 3 çš„é¢„æœŸå‡å°‘æ¯”ä¾‹)
        estimated_reduction = 0.40  # 40% å‡å°‘
        
        if not config.include_reasoning:
            estimated_reduction += 0.10  # é¢å¤– 10%
        
        if config.max_reply_tokens < 100:
            estimated_reduction += 0.05  # é¢å¤– 5%
        
        optimized_cost = current_stats["total_cost"] * (1 - estimated_reduction)
        
        return {
            "current_daily_cost": current_stats["total_cost"],
            "optimized_daily_cost": optimized_cost,
            "estimated_savings": current_stats["total_cost"] - optimized_cost,
            "reduction_percentage": estimated_reduction * 100
        }
```

---

### 6. é…ç½®ç®¡ç†ç•Œé¢ âš™ï¸

**ç›®æ ‡**: å¯è§†åŒ–é…ç½®ç®¡ç†

**åŠŸèƒ½**:
- Web ç•Œé¢é…ç½®ç¼–è¾‘
- é…ç½®ç‰ˆæœ¬ç®¡ç†
- é…ç½®å›æ»š
- é…ç½®å¯¹æ¯”

**å®ç°**:
```python
# app/api/config_management.py

from fastapi import APIRouter, HTTPException

router = APIRouter(prefix="/api/config")

@router.get("/current")
async def get_current_config():
    """è·å–å½“å‰é…ç½®"""
    return {
        "prompt": settings.prompt.dict(),
        "llm": settings.llm.dict(),
        "orchestrator": settings.orchestrator.dict()
    }

@router.post("/update")
async def update_config(config: PromptConfig):
    """æ›´æ–°é…ç½®"""
    # éªŒè¯é…ç½®
    if not validate_config(config):
        raise HTTPException(400, "Invalid configuration")
    
    # ä¿å­˜æ—§é…ç½®
    old_config = settings.prompt
    
    # åº”ç”¨æ–°é…ç½®
    settings.prompt = config
    
    # è®°å½•å˜æ›´
    await config_history.save({
        "timestamp": datetime.now(),
        "old_config": old_config,
        "new_config": config,
        "user": "admin"
    })
    
    return {"status": "success", "config": config.dict()}

@router.post("/rollback/{version}")
async def rollback_config(version: int):
    """å›æ»šé…ç½®"""
    # è·å–å†å²é…ç½®
    history = await config_history.get(version)
    
    if not history:
        raise HTTPException(404, "Version not found")
    
    # å›æ»š
    settings.prompt = history["old_config"]
    
    return {"status": "success", "config": history["old_config"].dict()}
```

---

## ğŸ“… å®æ–½ä¼˜å…ˆçº§

### é«˜ä¼˜å…ˆçº§ (ç«‹å³å®æ–½)
1. **Token ä½¿ç”¨ç›‘æ§** - äº†è§£å½“å‰çŠ¶æ€
2. **è´¨é‡ç›‘æ§** - ç¡®ä¿ä¼˜åŒ–ä¸å½±å“è´¨é‡

### ä¸­ä¼˜å…ˆçº§ (1-2 å‘¨å†…)
3. **A/B æµ‹è¯•æ¡†æ¶** - ç³»ç»ŸåŒ–æµ‹è¯•
4. **æˆæœ¬é¢„æµ‹** - é¢„ç®—ç®¡ç†

### ä½ä¼˜å…ˆçº§ (æœ‰æ—¶é—´å†åš)
5. **åŠ¨æ€ä¼˜åŒ–** - è‡ªåŠ¨åŒ–ä¼˜åŒ–
6. **é…ç½®ç®¡ç†ç•Œé¢** - æå‡æ˜“ç”¨æ€§

---

## ğŸ¯ æˆåŠŸæ ‡å‡†

- âœ… ç›‘æ§ç³»ç»Ÿæ­£å¸¸è¿è¡Œ
- âœ… èƒ½å¤Ÿå®æ—¶æŸ¥çœ‹ token ä½¿ç”¨
- âœ… A/B æµ‹è¯•æ¡†æ¶å¯ç”¨
- âœ… è´¨é‡ç›‘æ§æ— å‘Šè­¦
- âœ… æˆæœ¬åœ¨é¢„ç®—å†…

---

## ğŸ“š å‚è€ƒèµ„æ–™

- Phase 3 å®ŒæˆæŠ¥å‘Š: `PHASE3_COMPLETION_REPORT.md`
- ç”Ÿäº§éªŒè¯è®¡åˆ’: `PRODUCTION_VALIDATION.md`
- Token ä¼˜åŒ–åˆ†æ: `TOKEN_OPTIMIZATION_ANALYSIS.md`

---

**åˆ›å»ºæ—¥æœŸ**: 2026-01-22  
**æœ€åæ›´æ–°**: 2026-01-22  
**ç‰ˆæœ¬**: 1.0
